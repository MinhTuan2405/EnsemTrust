# EnsemTrust: End-to-End Fake News Detection Platform

<div align="center">

![Architecture Overview](./image/architecture_overview.png)

**An enterprise-grade data engineering and machine learning platform for automated fake news detection**

[ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t](#tiáº¿ng-viá»‡t) | [ğŸ‡¬ğŸ‡§ English](#english)

</div>

---

## English 

### Table of Contents
- [Dataset](#dataset)
- [Introduction](#introduction)
- [Key Features](#key-features)
- [Architecture](#architecture)
  - [Architecture Overview](#architecture-overview)
  - [Data Lineage](#data-lineage)
- [Technology Stack](#technology-stack)
- [Prerequisites](#prerequisites)
- [Installation Guide](#installation-guide)
  - [GPU Setup for Machine Learning](#gpu-setup-for-machine-learning)
- [Running the Project](#running-the-project)
- [Project Structure](#project-structure)
- [Development Team](#development-team)

---

### Dataset

This project uses the **Fake News Detection Dataset** from Kaggle:

**Dataset Source:** [Fake News Detection Datasets on Kaggle](https://www.kaggle.com/datasets/emineyetm/fake-news-detection-datasets/data)

The dataset contains news articles labeled as fake or real, which are used to train and evaluate the ensemble machine learning models in this platform.

---

### Introduction

**EnsemTrust** is a comprehensive fake news detection platform built using modern data engineering practices and machine learning techniques. The project implements a complete data pipeline from ingestion to visualization, leveraging distributed computing, lakehouse architecture, and ensemble learning models to accurately classify news articles as genuine or fake.

This platform demonstrates the integration of cutting-edge technologies including Apache Spark, Delta Lake, Dagster orchestration, and GPU-accelerated machine learning, all containerized using Docker for seamless deployment.

---

### Key Features

**Data Engineering Pipeline:**
- **Multi-layer Data Architecture**: Bronze (raw), Silver (cleaned), Gold (curated) layers following medallion architecture
- **Automated Data Orchestration**: Dagster-based workflow management with dependency tracking and lineage visualization
- **Distributed Processing**: Apache Spark for large-scale data transformation and feature engineering
- **Lakehouse Architecture**: Delta Lake for ACID transactions and time travel capabilities
- **Object Storage**: MinIO S3-compatible storage for scalable data management

**Machine Learning Pipeline:**
- **Ensemble Learning**: Combination of SVM, Logistic Regression, and LightGBM models
- **Advanced Feature Engineering**: TF-IDF, sentence transformers (BERT embeddings), and handcrafted text features
- **GPU Acceleration**: CUDA-enabled training for faster model development
- **Model Versioning**: Automatic model artifact storage in MinIO
- **Real-time Inference**: Streamlit-based interactive web application

**Data Visualization & Analytics:**
- **Interactive Dashboards**: Metabase integration for business intelligence
- **Query Engine**: Trino for fast SQL analytics on lakehouse data
- **Data Catalog**: CloudBeaver for database management and exploration
- **Pipeline Monitoring**: Dagster UI for real-time pipeline observability

---

### Architecture

#### Architecture Overview

![Architecture Overview](./image/architecture_overview.png)

The platform follows a modern lakehouse architecture with the following components:

**Data Ingestion Layer:**
- Files uploaded to MinIO landing zone
- Automated detection via Dagster file sensors
- Raw data ingestion to Bronze layer

**Data Processing Layer:**
- **Bronze Layer**: Raw data storage with minimal transformations
  
  ![Bronze Layer](./image/bronze_layer.svg)

- **Silver Layer**: Data cleaning, deduplication, and schema enforcement using Apache Spark
  
  ![Silver Layer](./image/silver_layer.svg)

- **Gold Layer**: Curated datasets stored as Delta tables for analytics
  
  ![Gold Layer](./image/gold_layer.svg)

**Machine Learning Layer:**
- Feature engineering with handcrafted and deep learning features
- Multi-model training (SVM, Logistic Regression, LightGBM)
- Stacking ensemble for improved accuracy
- Model evaluation and storage

![Machine Learning Layer](./image/machine_learning_layer.svg)

**Serving Layer:**
- Trino query engine for SQL-based analytics
- Metabase for BI dashboards
- Streamlit for real-time predictions
- CloudBeaver for data exploration

#### Data Lineage

![Dagster Lineage](./image/dagster_lineage_overview.svg)

The data lineage graph shows complete traceability from raw data ingestion through transformation to machine learning model deployment, ensuring data quality and reproducibility.

---

### Technology Stack

**Orchestration & Workflow:**
- **Dagster**: Modern data orchestrator for pipeline management
- **Docker & Docker Compose**: Containerization and multi-service orchestration

**Data Storage & Processing:**
- **MinIO**: S3-compatible object storage
- **PostgreSQL**: Metadata storage and Hive Metastore backend
- **Apache Spark 3.5.7**: Distributed data processing
- **Delta Lake**: ACID-compliant data lakehouse storage format
- **Apache Hive Metastore**: Centralized metadata repository

**Query & Analytics:**
- **Trino**: Distributed SQL query engine
- **Metabase**: Business intelligence and visualization
- **CloudBeaver**: Universal database management tool

**Machine Learning:**
- **Python 3.10**: Core programming language
- **PyTorch**: Deep learning framework with CUDA support
- **Transformers**: Hugging Face library for NLP models
- **Sentence-Transformers**: Pre-trained sentence embeddings
- **Scikit-learn**: Classical machine learning algorithms
- **LightGBM**: Gradient boosting framework

**Web Application:**
- **Streamlit**: Interactive web application framework

**Infrastructure:**
- **NVIDIA CUDA 11.8**: GPU acceleration for ML training
- **Poetry**: Python dependency management

---

### Prerequisites

Before installing the project, ensure you have the following:

**Required Software:**
- **Docker Desktop** (with WSL 2 backend on Windows)
- **Docker Compose** v2.0+
- **Git** for version control
- Minimum **16GB RAM** (32GB recommended)
- **50GB free disk space**

**For GPU Support (Optional but Recommended):**
- NVIDIA GPU with CUDA Compute Capability 3.5+
- NVIDIA Docker runtime installed
- Latest NVIDIA drivers

**System Requirements:**
- Windows 10/11, macOS 11+, or Linux (Ubuntu 20.04+)
- Multi-core processor (4+ cores recommended)

---

### Installation Guide

#### Step 1: Clone the Repository

```bash
git clone https://github.com/MinhTuan2405/EnsemTrust.git
cd EnsemTrust
```

#### Step 2: Download Required JAR Files

The project requires specific JAR files for Hadoop AWS integration and PostgreSQL connectivity. Run the appropriate script:

**On Linux/macOS:**
```bash
chmod +x Script/jardownloader.sh
./Script/jardownloader.sh
```

**On Windows (PowerShell):**
```powershell
.\Script\jardownloader.ps1
```

This will download:
- `hadoop-aws-3.3.6.jar`
- `aws-java-sdk-bundle-1.12.262.jar`
- `postgresql-42.7.8.jar`

#### Step 3: Configure Environment Variables

Create a `.env` file in the project root:

```bash
cp .env.example .env
```

Edit `.env` with your configurations:

```env
# PostgreSQL Configuration
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin123
POSTGRES_DB=ensemtrust
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# MinIO Configuration
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=admin123
MINIO_PORT=9000
MINIO_CONSOLE_PORT=9001

# Dagster Configuration
DAGSTER_PORT=3000
DAGSTER_HOME=/opt/dagster/dagster_home/dagster-project

# Trino Configuration
TRINO_PORT=8090

# Metabase Configuration
METABASE_DB=metabase

# Feature Engineering
TFIDF_MAX_FEATURES=5000
SVD_COMPONENTS=300
RANDOM_STATE=42

# AWS/S3 Configuration (for MinIO)
AWS_ACCESS_KEY_ID=admin
AWS_SECRET_ACCESS_KEY=admin123
AWS_DEFAULT_REGION=us-east-1
AWS_S3_ENDPOINT=http://minio:9000
```

#### Step 4: GPU Setup for Machine Learning

**On Linux:**

1. Install NVIDIA Docker runtime:
```bash
# Add NVIDIA Docker repository
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

# Install nvidia-docker2
sudo apt-get update
sudo apt-get install -y nvidia-docker2

# Restart Docker
sudo systemctl restart docker
```

2. Verify GPU access:
```bash
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

**On Windows with WSL 2:**

1. Install NVIDIA drivers for Windows (support WSL 2)
2. Enable WSL 2 and install Ubuntu distribution
3. Inside WSL 2:
```bash
# Install NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update && sudo apt-get install -y nvidia-docker2
```

4. Update Docker Desktop settings:
   - Open Docker Desktop â†’ Settings â†’ Resources â†’ WSL Integration
   - Enable integration with your WSL distribution

**Verify GPU Setup:**
```bash
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

You should see your GPU information displayed.

#### Step 5: Build and Start Services

```bash
# Build all Docker images
docker-compose build

# Start all services
docker-compose up -d

# Check service status
docker-compose ps
```

Wait for all services to be healthy (this may take 5-10 minutes on first run).

#### Step 6: Initialize Data Buckets

The MinIO buckets (landing, bronze, silver, gold, models) are automatically created by the `mc` service. Verify by accessing MinIO console at `http://localhost:9001` with credentials from `.env`.

---

### Running the Project

#### 1. Access Dagster UI

Open `http://localhost:3000` to access the Dagster orchestration interface.

**Run the Complete Pipeline:**

1. Navigate to "Assets" tab
2. Click "Materialize all" to run the entire pipeline, or
3. Select specific assets to run individual components

**Pipeline Execution Order:**
1. **Bronze Layer**: `ingest_new_file` - Upload CSV files to MinIO landing zone first
2. **Silver Layer**: `load_fake_dataset` â†’ `load_true_dataset` â†’ `transform_news_dataset`
3. **Gold Layer**: `gold_news_dataset`
4. **ML Pipeline**: 
   - `load_data_for_ml` â†’ `feature_engineering` â†’ `combine_features`
   - `train_svm` / `train_logistic_regression` / `train_lightgbm`
   - `train_stacking_ensemble`

#### 2. Upload Dataset

Place your CSV files (fake news and real news datasets) in MinIO landing zone:

**Via MinIO Console** (`http://localhost:9001`):
- Login with credentials from `.env`
- Navigate to `landing` bucket
- Upload CSV files

**Via MinIO CLI**:
```bash
docker exec -it mc sh
mc alias set local http://minio:9000 admin admin123
mc cp /path/to/your/dataset.csv local/landing/
```

#### 3. Monitor Pipeline Execution

**Dagster UI** (`http://localhost:3000`):
- View real-time logs
- Check asset materialization status
- Visualize data lineage

**Spark UI** (`http://localhost:8082`):
- Monitor Spark jobs
- View worker nodes and resource usage

#### 4. Query Data with Trino

Access CloudBeaver at `http://localhost:8978`:
1. Create Trino connection:
   - Host: `trino`
   - Port: `8080`
   - Catalog: `delta` or `hive`

2. Query example:
```sql
SELECT label, COUNT(*) as count
FROM delta.default.news_dataset
GROUP BY label;
```

#### 5. Visualize with Metabase

Access Metabase at `http://localhost:3007`:
1. Complete initial setup
2. Add Trino as data source
3. Create dashboards and visualizations

#### 6. Test Predictions with Streamlit

Access the web application at `http://localhost:8501`:
1. Enter news article text
2. Click "PhÃ¢n tÃ­ch" (Analyze)
3. View prediction results with confidence scores

**Example Input:**
```
President announces new policy to reduce inflation by 50% next month
```

---

### Project Structure

```
ensemtrust/
â”œâ”€â”€ pipeline/                      # Dagster pipeline code
â”‚   â”œâ”€â”€ assets/                    # Asset definitions
â”‚   â”‚   â”œâ”€â”€ bronze/                # Bronze layer ingestion
â”‚   â”‚   â”œâ”€â”€ silver/                # Silver layer transformation
â”‚   â”‚   â”œâ”€â”€ gold/                  # Gold layer Delta tables
â”‚   â”‚   â””â”€â”€ machine_learning/      # ML training pipeline
â”‚   â”œâ”€â”€ jobs/                      # Dagster jobs
â”‚   â”œâ”€â”€ resources/                 # Resource definitions (MinIO, etc.)
â”‚   â”œâ”€â”€ sensors/                   # File sensors
â”‚   â””â”€â”€ utils/                     # Utility functions
â”‚       â”œâ”€â”€ feature_engineer.py    # Feature engineering logic
â”‚       â”œâ”€â”€ models.py              # ML model definitions
â”‚       â””â”€â”€ spark.py               # Spark session management
â”œâ”€â”€ streamlit/                     # Web application
â”‚   â””â”€â”€ app.py                     # Streamlit UI
â”œâ”€â”€ config/                        # Configuration files
â”‚   â”œâ”€â”€ hive/                      # Hive Metastore config
â”‚   â””â”€â”€ trino/                     # Trino catalog config
â”œâ”€â”€ data/                          # Persistent data volumes
â”‚   â”œâ”€â”€ minio/                     # Object storage
â”‚   â”œâ”€â”€ postgres/                  # Database storage
â”‚   â””â”€â”€ dagster/                   # Dagster storage
â”œâ”€â”€ image/                         # Architecture diagrams
â”œâ”€â”€ init-scripts/                  # Initialization scripts
â”œâ”€â”€ jars/                          # Java dependencies
â”œâ”€â”€ notebooks/                     # Jupyter notebooks for EDA
â”œâ”€â”€ Script/                        # Utility scripts
â”œâ”€â”€ docker-compose.yml             # Service orchestration
â”œâ”€â”€ Dockerfile.dagster             # Dagster container
â”œâ”€â”€ Dockerfile.spark               # Spark container
â”œâ”€â”€ Dockerfile.streamlit           # Streamlit container
â”œâ”€â”€ pyproject.toml                 # Python dependencies
â”œâ”€â”€ workspace.yaml                 # Dagster workspace config
â””â”€â”€ README.md                      # This file
```

---

### Development Team

**Project Team:**
- **Nguyá»…n HÃ  Minh Tuáº¥n** - Data Engineer & ML Engineer
- **Tráº§n Phan Thanh TÃ¹ng** - Data Engineer
- **Tráº§n Nguyá»…n Äá»©c Trung** - Data Engineer

**Institution:**  
University of Information Technology (UIT) - Vietnam National University Ho Chi Minh City

**Supervisor:**  
**Dr. HÃ  Minh TÃ¢n**  
Lecturer, Faculty of Information Science and Engineering  
University of Information Technology (UIT)

**Contact:**
- GitHub: [MinhTuan2405](https://github.com/MinhTuan2405)
- Email: tuannguyen.02042005@gmail.com

---

### License

This project is developed for educational purposes 

---

### Acknowledgments

Special thanks to Dr. HÃ  Minh TÃ¢n for guidance and mentorship throughout the development of this project.

---

<div align="center">

**Built with â¤ï¸ by UIT Students**

</div>

---
---
---

## Tiáº¿ng Viá»‡t

### Má»¥c lá»¥c
- [Bá»™ dá»¯ liá»‡u](#bá»™-dá»¯-liá»‡u)
- [Giá»›i thiá»‡u](#giá»›i-thiá»‡u)
- [CÃ¡c tÃ­nh nÄƒng chÃ­nh](#cÃ¡c-tÃ­nh-nÄƒng-chÃ­nh)
- [Kiáº¿n trÃºc](#kiáº¿n-trÃºc)
  - [Kiáº¿n trÃºc tá»•ng quan](#kiáº¿n-trÃºc-tá»•ng-quan)
  - [Data Lineage](#data-lineage-vi)
- [CÃ¡c cÃ´ng nghá»‡ chÃ­nh sá»­ dá»¥ng](#cÃ¡c-cÃ´ng-nghá»‡-chÃ­nh-sá»­-dá»¥ng)
- [YÃªu cáº§u trÆ°á»›c khi cÃ i Ä‘áº·t](#yÃªu-cáº§u-trÆ°á»›c-khi-cÃ i-Ä‘áº·t)
- [HÆ°á»›ng dáº«n cÃ i Ä‘áº·t dá»± Ã¡n](#hÆ°á»›ng-dáº«n-cÃ i-Ä‘áº·t-dá»±-Ã¡n)
  - [Setup GPU cho Machine Learning](#setup-gpu-cho-machine-learning)
- [CÃ¡ch cháº¡y dá»± Ã¡n](#cÃ¡ch-cháº¡y-dá»±-Ã¡n)
- [Cáº¥u trÃºc dá»± Ã¡n](#cáº¥u-trÃºc-dá»±-Ã¡n)
- [NhÃ³m phÃ¡t triá»ƒn](#nhÃ³m-phÃ¡t-triá»ƒn)

---

### Bá»™ dá»¯ liá»‡u

Dá»± Ã¡n nÃ y sá»­ dá»¥ng **Bá»™ dá»¯ liá»‡u phÃ¡t hiá»‡n tin giáº£ (Fake News Detection Dataset)** tá»« Kaggle:

**Nguá»“n dá»¯ liá»‡u:** [Fake News Detection Datasets trÃªn Kaggle](https://www.kaggle.com/datasets/emineyetm/fake-news-detection-datasets/data)

Bá»™ dá»¯ liá»‡u chá»©a cÃ¡c bÃ i bÃ¡o Ä‘Æ°á»£c gáº¯n nhÃ£n lÃ  tin giáº£ hoáº·c tin tháº­t, Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh machine learning ensemble trong ná»n táº£ng nÃ y.

---

### Giá»›i thiá»‡u

**EnsemTrust** lÃ  má»™t ná»n táº£ng phÃ¡t hiá»‡n tin giáº£ toÃ n diá»‡n Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn cÃ¡c phÆ°Æ¡ng phÃ¡p data engineering hiá»‡n Ä‘áº¡i vÃ  ká»¹ thuáº­t machine learning. Dá»± Ã¡n triá»ƒn khai má»™t pipeline dá»¯ liá»‡u hoÃ n chá»‰nh tá»« khÃ¢u thu tháº­p Ä‘áº¿n trá»±c quan hÃ³a, táº­n dá»¥ng Ä‘iá»‡n toÃ¡n phÃ¢n tÃ¡n, kiáº¿n trÃºc lakehouse, vÃ  cÃ¡c mÃ´ hÃ¬nh ensemble learning Ä‘á»ƒ phÃ¢n loáº¡i chÃ­nh xÃ¡c cÃ¡c bÃ i bÃ¡o lÃ  tháº­t hay giáº£.

Ná»n táº£ng nÃ y thá»ƒ hiá»‡n sá»± tÃ­ch há»£p cÃ¡c cÃ´ng nghá»‡ tiÃªn tiáº¿n bao gá»“m Apache Spark, Delta Lake, Dagster orchestration, vÃ  machine learning tÄƒng tá»‘c GPU, táº¥t cáº£ Ä‘Æ°á»£c Ä‘Ã³ng gÃ³i báº±ng Docker Ä‘á»ƒ triá»ƒn khai dá»… dÃ ng.

---

### CÃ¡c tÃ­nh nÄƒng chÃ­nh

**Pipeline Data Engineering:**
- **Kiáº¿n trÃºc dá»¯ liá»‡u Ä‘a táº§ng**: CÃ¡c lá»›p Bronze (thÃ´), Silver (Ä‘Ã£ lÃ m sáº¡ch), Gold (Ä‘Æ°á»£c tá»• chá»©c) theo kiáº¿n trÃºc medallion
- **Tá»± Ä‘á»™ng hÃ³a luá»“ng dá»¯ liá»‡u**: Quáº£n lÃ½ workflow dá»±a trÃªn Dagster vá»›i theo dÃµi phá»¥ thuá»™c vÃ  trá»±c quan hÃ³a lineage
- **Xá»­ lÃ½ phÃ¢n tÃ¡n**: Apache Spark cho chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u quy mÃ´ lá»›n vÃ  feature engineering
- **Kiáº¿n trÃºc Lakehouse**: Delta Lake cho ACID transactions vÃ  kháº£ nÄƒng time travel
- **Object Storage**: MinIO tÆ°Æ¡ng thÃ­ch S3 cho quáº£n lÃ½ dá»¯ liá»‡u cÃ³ kháº£ nÄƒng má»Ÿ rá»™ng

**Pipeline Machine Learning:**
- **Ensemble Learning**: Káº¿t há»£p cÃ¡c mÃ´ hÃ¬nh SVM, Logistic Regression, vÃ  LightGBM
- **Feature Engineering nÃ¢ng cao**: TF-IDF, sentence transformers (BERT embeddings), vÃ  cÃ¡c Ä‘áº·c trÆ°ng vÄƒn báº£n thá»§ cÃ´ng
- **TÄƒng tá»‘c GPU**: Huáº¥n luyá»‡n há»— trá»£ CUDA cho phÃ¡t triá»ƒn mÃ´ hÃ¬nh nhanh hÆ¡n
- **Quáº£n lÃ½ phiÃªn báº£n mÃ´ hÃ¬nh**: LÆ°u trá»¯ tá»± Ä‘á»™ng cÃ¡c artifact mÃ´ hÃ¬nh trong MinIO
- **Dá»± Ä‘oÃ¡n thá»i gian thá»±c**: á»¨ng dá»¥ng web tÆ°Æ¡ng tÃ¡c dá»±a trÃªn Streamlit

**Trá»±c quan hÃ³a dá»¯ liá»‡u & PhÃ¢n tÃ­ch:**
- **Dashboard tÆ°Æ¡ng tÃ¡c**: TÃ­ch há»£p Metabase cho business intelligence
- **Query Engine**: Trino cho phÃ¢n tÃ­ch SQL nhanh trÃªn dá»¯ liá»‡u lakehouse
- **Data Catalog**: CloudBeaver cho quáº£n lÃ½ vÃ  khÃ¡m phÃ¡ cÆ¡ sá»Ÿ dá»¯ liá»‡u
- **GiÃ¡m sÃ¡t Pipeline**: Dagster UI cho kháº£ nÄƒng quan sÃ¡t pipeline thá»i gian thá»±c

---

### Kiáº¿n trÃºc

#### Kiáº¿n trÃºc tá»•ng quan

![Architecture Overview](./image/architecture_overview.png)

Ná»n táº£ng tuÃ¢n theo kiáº¿n trÃºc lakehouse hiá»‡n Ä‘áº¡i vá»›i cÃ¡c thÃ nh pháº§n sau:

**Lá»›p thu tháº­p dá»¯ liá»‡u (Data Ingestion Layer):**
- Files Ä‘Æ°á»£c táº£i lÃªn landing zone cá»§a MinIO
- PhÃ¡t hiá»‡n tá»± Ä‘á»™ng thÃ´ng qua Dagster file sensors
- Thu tháº­p dá»¯ liá»‡u thÃ´ vÃ o lá»›p Bronze

**Lá»›p xá»­ lÃ½ dá»¯ liá»‡u (Data Processing Layer):**
- **Lá»›p Bronze**: LÆ°u trá»¯ dá»¯ liá»‡u thÃ´ vá»›i chuyá»ƒn Ä‘á»•i tá»‘i thiá»ƒu
  
  ![Bronze Layer](./image/bronze_layer.svg)

- **Lá»›p Silver**: LÃ m sáº¡ch dá»¯ liá»‡u, loáº¡i bá» trÃ¹ng láº·p, vÃ  Ã¡p dá»¥ng schema sá»­ dá»¥ng Apache Spark
  
  ![Silver Layer](./image/silver_layer.svg)

- **Lá»›p Gold**: Datasets Ä‘Æ°á»£c tá»• chá»©c lÆ°u trá»¯ dÆ°á»›i dáº¡ng Delta tables cho phÃ¢n tÃ­ch
  
  ![Gold Layer](./image/gold_layer.svg)

**Lá»›p Machine Learning:**
- Feature engineering vá»›i cÃ¡c Ä‘áº·c trÆ°ng thá»§ cÃ´ng vÃ  deep learning
- Huáº¥n luyá»‡n nhiá»u mÃ´ hÃ¬nh (SVM, Logistic Regression, LightGBM)
- Stacking ensemble Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c
- ÄÃ¡nh giÃ¡ vÃ  lÆ°u trá»¯ mÃ´ hÃ¬nh

![Machine Learning Layer](./image/machine_learning_layer.svg)

**Lá»›p phá»¥c vá»¥ (Serving Layer):**
- Trino query engine cho phÃ¢n tÃ­ch dá»±a trÃªn SQL
- Metabase cho BI dashboards
- Streamlit cho dá»± Ä‘oÃ¡n thá»i gian thá»±c
- CloudBeaver cho khÃ¡m phÃ¡ dá»¯ liá»‡u

#### Data Lineage (VI)

![Dagster Lineage](./image/dagster_lineage_overview.svg)

Biá»ƒu Ä‘á»“ data lineage hiá»ƒn thá»‹ kháº£ nÄƒng truy váº¿t hoÃ n toÃ n tá»« thu tháº­p dá»¯ liá»‡u thÃ´ qua chuyá»ƒn Ä‘á»•i Ä‘áº¿n triá»ƒn khai mÃ´ hÃ¬nh machine learning, Ä‘áº£m báº£o cháº¥t lÆ°á»£ng dá»¯ liá»‡u vÃ  kháº£ nÄƒng tÃ¡i táº¡o.

---

### CÃ¡c cÃ´ng nghá»‡ chÃ­nh sá»­ dá»¥ng

**Orchestration & Workflow:**
- **Dagster**: Orchestrator dá»¯ liá»‡u hiá»‡n Ä‘áº¡i cho quáº£n lÃ½ pipeline
- **Docker & Docker Compose**: ÄÃ³ng gÃ³i container vÃ  orchestration nhiá»u service

**LÆ°u trá»¯ & Xá»­ lÃ½ dá»¯ liá»‡u:**
- **MinIO**: Object storage tÆ°Æ¡ng thÃ­ch S3
- **PostgreSQL**: LÆ°u trá»¯ metadata vÃ  backend cho Hive Metastore
- **Apache Spark 3.5.7**: Xá»­ lÃ½ dá»¯ liá»‡u phÃ¢n tÃ¡n
- **Delta Lake**: Äá»‹nh dáº¡ng lÆ°u trá»¯ data lakehouse tuÃ¢n thá»§ ACID
- **Apache Hive Metastore**: Kho metadata táº­p trung

**Query & Analytics:**
- **Trino**: Distributed SQL query engine
- **Metabase**: Business intelligence vÃ  trá»±c quan hÃ³a
- **CloudBeaver**: CÃ´ng cá»¥ quáº£n lÃ½ database Ä‘a nÄƒng

**Machine Learning:**
- **Python 3.10**: NgÃ´n ngá»¯ láº­p trÃ¬nh chÃ­nh
- **PyTorch**: Framework deep learning vá»›i há»— trá»£ CUDA
- **Transformers**: ThÆ° viá»‡n Hugging Face cho cÃ¡c mÃ´ hÃ¬nh NLP
- **Sentence-Transformers**: Pre-trained sentence embeddings
- **Scikit-learn**: Thuáº­t toÃ¡n machine learning cá»• Ä‘iá»ƒn
- **LightGBM**: Framework gradient boosting

**á»¨ng dá»¥ng Web:**
- **Streamlit**: Framework á»©ng dá»¥ng web tÆ°Æ¡ng tÃ¡c

**Háº¡ táº§ng:**
- **NVIDIA CUDA 11.8**: TÄƒng tá»‘c GPU cho huáº¥n luyá»‡n ML
- **Poetry**: Quáº£n lÃ½ dependencies Python

---

### YÃªu cáº§u trÆ°á»›c khi cÃ i Ä‘áº·t

TrÆ°á»›c khi cÃ i Ä‘áº·t dá»± Ã¡n, Ä‘áº£m báº£o báº¡n cÃ³:

**Pháº§n má»m báº¯t buá»™c:**
- **Docker Desktop** (vá»›i WSL 2 backend trÃªn Windows)
- **Docker Compose** v2.0+
- **Git** cho version control
- Tá»‘i thiá»ƒu **16GB RAM** (khuyáº¿n nghá»‹ 32GB)
- **50GB dung lÆ°á»£ng á»• Ä‘Ä©a trá»‘ng**

**Äá»ƒ há»— trá»£ GPU (TÃ¹y chá»n nhÆ°ng Ä‘Æ°á»£c khuyáº¿n nghá»‹):**
- NVIDIA GPU vá»›i CUDA Compute Capability 3.5+
- NVIDIA Docker runtime Ä‘Ã£ cÃ i Ä‘áº·t
- Driver NVIDIA má»›i nháº¥t

**YÃªu cáº§u há»‡ thá»‘ng:**
- Windows 10/11, macOS 11+, hoáº·c Linux (Ubuntu 20.04+)
- Bá»™ xá»­ lÃ½ Ä‘a lÃµi (khuyáº¿n nghá»‹ 4+ lÃµi)

---

### HÆ°á»›ng dáº«n cÃ i Ä‘áº·t dá»± Ã¡n

#### BÆ°á»›c 1: Clone Repository

```bash
git clone https://github.com/MinhTuan2405/EnsemTrust.git
cd EnsemTrust
```

#### BÆ°á»›c 2: Táº£i cÃ¡c file JAR cáº§n thiáº¿t

Dá»± Ã¡n yÃªu cáº§u cÃ¡c file JAR cá»¥ thá»ƒ cho tÃ­ch há»£p Hadoop AWS vÃ  káº¿t ná»‘i PostgreSQL. Cháº¡y script phÃ¹ há»£p:

**TrÃªn Linux/macOS:**
```bash
chmod +x Script/jardownloader.sh
./Script/jardownloader.sh
```

**TrÃªn Windows (PowerShell):**
```powershell
.\Script\jardownloader.ps1
```

Script sáº½ táº£i xuá»‘ng:
- `hadoop-aws-3.3.6.jar`
- `aws-java-sdk-bundle-1.12.262.jar`
- `postgresql-42.7.8.jar`

#### BÆ°á»›c 3: Cáº¥u hÃ¬nh biáº¿n mÃ´i trÆ°á»ng

Táº¡o file `.env` trong thÆ° má»¥c gá»‘c cá»§a dá»± Ã¡n:

```bash
cp .env.example .env
```

Chá»‰nh sá»­a `.env` vá»›i cáº¥u hÃ¬nh cá»§a báº¡n:

```env
# PostgreSQL Configuration
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin123
POSTGRES_DB=ensemtrust
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# MinIO Configuration
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=admin123
MINIO_PORT=9000
MINIO_CONSOLE_PORT=9001

# Dagster Configuration
DAGSTER_PORT=3000
DAGSTER_HOME=/opt/dagster/dagster_home/dagster-project

# Trino Configuration
TRINO_PORT=8090

# Metabase Configuration
METABASE_DB=metabase

# Feature Engineering
TFIDF_MAX_FEATURES=5000
SVD_COMPONENTS=300
RANDOM_STATE=42

# AWS/S3 Configuration (for MinIO)
AWS_ACCESS_KEY_ID=admin
AWS_SECRET_ACCESS_KEY=admin123
AWS_DEFAULT_REGION=us-east-1
AWS_S3_ENDPOINT=http://minio:9000
```

#### BÆ°á»›c 4: Setup GPU cho Machine Learning

**TrÃªn Linux:**

1. CÃ i Ä‘áº·t NVIDIA Docker runtime:
```bash
# ThÃªm repository NVIDIA Docker
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

# CÃ i Ä‘áº·t nvidia-docker2
sudo apt-get update
sudo apt-get install -y nvidia-docker2

# Khá»Ÿi Ä‘á»™ng láº¡i Docker
sudo systemctl restart docker
```

2. XÃ¡c minh quyá»n truy cáº­p GPU:
```bash
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

**TrÃªn Windows vá»›i WSL 2:**

1. CÃ i Ä‘áº·t driver NVIDIA cho Windows (há»— trá»£ WSL 2)
2. Báº­t WSL 2 vÃ  cÃ i Ä‘áº·t báº£n phÃ¢n phá»‘i Ubuntu
3. Trong WSL 2:
```bash
# CÃ i Ä‘áº·t NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update && sudo apt-get install -y nvidia-docker2
```

4. Cáº­p nháº­t cÃ i Ä‘áº·t Docker Desktop:
   - Má»Ÿ Docker Desktop â†’ Settings â†’ Resources â†’ WSL Integration
   - Báº­t tÃ­ch há»£p vá»›i báº£n phÃ¢n phá»‘i WSL cá»§a báº¡n

**Kiá»ƒm tra Setup GPU:**
```bash
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

Báº¡n sáº½ tháº¥y thÃ´ng tin GPU cá»§a mÃ¬nh Ä‘Æ°á»£c hiá»ƒn thá»‹.

#### BÆ°á»›c 5: Build vÃ  khá»Ÿi Ä‘á»™ng cÃ¡c services

```bash
# Build táº¥t cáº£ Docker images
docker-compose build

# Khá»Ÿi Ä‘á»™ng táº¥t cáº£ services
docker-compose up -d

# Kiá»ƒm tra tráº¡ng thÃ¡i services
docker-compose ps
```

Chá» táº¥t cáº£ cÃ¡c services á»Ÿ tráº¡ng thÃ¡i healthy (cÃ³ thá»ƒ máº¥t 5-10 phÃºt láº§n cháº¡y Ä‘áº§u tiÃªn).

#### BÆ°á»›c 6: Khá»Ÿi táº¡o Data Buckets

CÃ¡c buckets MinIO (landing, bronze, silver, gold, models) Ä‘Æ°á»£c tá»± Ä‘á»™ng táº¡o bá»Ÿi service `mc`. XÃ¡c minh báº±ng cÃ¡ch truy cáº­p MinIO console táº¡i `http://localhost:9001` vá»›i thÃ´ng tin Ä‘Äƒng nháº­p tá»« `.env`.

---

### CÃ¡ch cháº¡y dá»± Ã¡n

#### 1. Truy cáº­p Dagster UI

Má»Ÿ `http://localhost:3000` Ä‘á»ƒ truy cáº­p giao diá»‡n orchestration Dagster.

**Cháº¡y Pipeline hoÃ n chá»‰nh:**

1. Äiá»u hÆ°á»›ng Ä‘áº¿n tab "Assets"
2. Click "Materialize all" Ä‘á»ƒ cháº¡y toÃ n bá»™ pipeline, hoáº·c
3. Chá»n cÃ¡c assets cá»¥ thá»ƒ Ä‘á»ƒ cháº¡y tá»«ng thÃ nh pháº§n riÃªng láº»

**Thá»© tá»± thá»±c thi Pipeline:**
1. **Lá»›p Bronze**: `ingest_new_file` - Táº£i files CSV lÃªn landing zone cá»§a MinIO trÆ°á»›c
2. **Lá»›p Silver**: `load_fake_dataset` â†’ `load_true_dataset` â†’ `transform_news_dataset`
3. **Lá»›p Gold**: `gold_news_dataset`
4. **ML Pipeline**: 
   - `load_data_for_ml` â†’ `feature_engineering` â†’ `combine_features`
   - `train_svm` / `train_logistic_regression` / `train_lightgbm`
   - `train_stacking_ensemble`

#### 2. Táº£i Dataset lÃªn

Äáº·t cÃ¡c file CSV cá»§a báº¡n (datasets tin giáº£ vÃ  tin tháº­t) vÃ o landing zone cá»§a MinIO:

**Qua MinIO Console** (`http://localhost:9001`):
- ÄÄƒng nháº­p vá»›i thÃ´ng tin tá»« `.env`
- Äiá»u hÆ°á»›ng Ä‘áº¿n bucket `landing`
- Táº£i lÃªn cÃ¡c file CSV

**Qua MinIO CLI**:
```bash
docker exec -it mc sh
mc alias set local http://minio:9000 admin admin123
mc cp /path/to/your/dataset.csv local/landing/
```

#### 3. GiÃ¡m sÃ¡t thá»±c thi Pipeline

**Dagster UI** (`http://localhost:3000`):
- Xem logs thá»i gian thá»±c
- Kiá»ƒm tra tráº¡ng thÃ¡i materialization cá»§a assets
- Trá»±c quan hÃ³a data lineage

**Spark UI** (`http://localhost:8082`):
- GiÃ¡m sÃ¡t Spark jobs
- Xem cÃ¡c worker nodes vÃ  má»©c sá»­ dá»¥ng tÃ i nguyÃªn

#### 4. Query dá»¯ liá»‡u vá»›i Trino

Truy cáº­p CloudBeaver táº¡i `http://localhost:8978`:
1. Táº¡o káº¿t ná»‘i Trino:
   - Host: `trino`
   - Port: `8080`
   - Catalog: `delta` hoáº·c `hive`

2. VÃ­ dá»¥ query:
```sql
SELECT label, COUNT(*) as count
FROM delta.default.news_dataset
GROUP BY label;
```

#### 5. Trá»±c quan hÃ³a vá»›i Metabase

Truy cáº­p Metabase táº¡i `http://localhost:3007`:
1. HoÃ n thÃ nh thiáº¿t láº­p ban Ä‘áº§u
2. ThÃªm Trino lÃ m nguá»“n dá»¯ liá»‡u
3. Táº¡o dashboards vÃ  visualizations

#### 6. Kiá»ƒm tra dá»± Ä‘oÃ¡n vá»›i Streamlit

Truy cáº­p á»©ng dá»¥ng web táº¡i `http://localhost:8501`:
1. Nháº­p vÄƒn báº£n bÃ i bÃ¡o
2. Click "PhÃ¢n tÃ­ch"
3. Xem káº¿t quáº£ dá»± Ä‘oÃ¡n vá»›i Ä‘iá»ƒm confidence

**VÃ­ dá»¥ Input:**
```
Tá»•ng thá»‘ng cÃ´ng bá»‘ chÃ­nh sÃ¡ch má»›i giáº£m láº¡m phÃ¡t 50% trong thÃ¡ng tá»›i
```

---

### Cáº¥u trÃºc dá»± Ã¡n

```
ensemtrust/
â”œâ”€â”€ pipeline/                      # MÃ£ Dagster pipeline
â”‚   â”œâ”€â”€ assets/                    # Äá»‹nh nghÄ©a assets
â”‚   â”‚   â”œâ”€â”€ bronze/                # Thu tháº­p lá»›p Bronze
â”‚   â”‚   â”œâ”€â”€ silver/                # Chuyá»ƒn Ä‘á»•i lá»›p Silver
â”‚   â”‚   â”œâ”€â”€ gold/                  # Delta tables lá»›p Gold
â”‚   â”‚   â””â”€â”€ machine_learning/      # Pipeline huáº¥n luyá»‡n ML
â”‚   â”œâ”€â”€ jobs/                      # Dagster jobs
â”‚   â”œâ”€â”€ resources/                 # Äá»‹nh nghÄ©a resources (MinIO, etc.)
â”‚   â”œâ”€â”€ sensors/                   # File sensors
â”‚   â””â”€â”€ utils/                     # HÃ m tiá»‡n Ã­ch
â”‚       â”œâ”€â”€ feature_engineer.py    # Logic feature engineering
â”‚       â”œâ”€â”€ models.py              # Äá»‹nh nghÄ©a mÃ´ hÃ¬nh ML
â”‚       â””â”€â”€ spark.py               # Quáº£n lÃ½ Spark session
â”œâ”€â”€ streamlit/                     # á»¨ng dá»¥ng web
â”‚   â””â”€â”€ app.py                     # Streamlit UI
â”œâ”€â”€ config/                        # Files cáº¥u hÃ¬nh
â”‚   â”œâ”€â”€ hive/                      # Cáº¥u hÃ¬nh Hive Metastore
â”‚   â””â”€â”€ trino/                     # Cáº¥u hÃ¬nh catalog Trino
â”œâ”€â”€ data/                          # Persistent data volumes
â”‚   â”œâ”€â”€ minio/                     # Object storage
â”‚   â”œâ”€â”€ postgres/                  # Database storage
â”‚   â””â”€â”€ dagster/                   # Dagster storage
â”œâ”€â”€ image/                         # SÆ¡ Ä‘á»“ kiáº¿n trÃºc
â”œâ”€â”€ init-scripts/                  # Scripts khá»Ÿi táº¡o
â”œâ”€â”€ jars/                          # Dependencies Java
â”œâ”€â”€ notebooks/                     # Jupyter notebooks cho EDA
â”œâ”€â”€ Script/                        # Utility scripts
â”œâ”€â”€ docker-compose.yml             # Orchestration services
â”œâ”€â”€ Dockerfile.dagster             # Container Dagster
â”œâ”€â”€ Dockerfile.spark               # Container Spark
â”œâ”€â”€ Dockerfile.streamlit           # Container Streamlit
â”œâ”€â”€ pyproject.toml                 # Dependencies Python
â”œâ”€â”€ workspace.yaml                 # Cáº¥u hÃ¬nh Dagster workspace
â””â”€â”€ README.md                      # File nÃ y
```

---

### NhÃ³m phÃ¡t triá»ƒn

**NhÃ³m dá»± Ã¡n:**
- **Nguyá»…n HÃ  Minh Tuáº¥n** - Data Engineer & ML Engineer
- **Tráº§n Phan Thanh TÃ¹ng** - Data Engineer
- **Tráº§n Nguyá»…n Äá»©c Trung** - Data Engineer

**ÄÆ¡n vá»‹:**  
TrÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡ ThÃ´ng tin (UIT) - Äáº¡i há»c Quá»‘c gia ThÃ nh phá»‘ Há»“ ChÃ­ Minh

**Giáº£ng viÃªn hÆ°á»›ng dáº«n:**  
**Tiáº¿n sÄ© HÃ  Minh TÃ¢n**  
Giáº£ng viÃªn, Khoa Khoa há»c vÃ  Ká»¹ thuáº­t ThÃ´ng tin  
TrÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡ ThÃ´ng tin (UIT)

**LiÃªn há»‡:**
- GitHub: [MinhTuan2405](https://github.com/MinhTuan2405)
- Email: tuannguyen.02042005@gmail.com

---

### Giáº¥y phÃ©p

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn cho má»¥c Ä‘Ã­ch giÃ¡o dá»¥c 

---

### Lá»i cáº£m Æ¡n

Xin chÃ¢n thÃ nh cáº£m Æ¡n Tiáº¿n sÄ© HÃ  Minh TÃ¢n Ä‘Ã£ hÆ°á»›ng dáº«n vÃ  há»— trá»£ trong suá»‘t quÃ¡ trÃ¬nh phÃ¡t triá»ƒn dá»± Ã¡n nÃ y.

---

<div align="center">

**ÄÆ°á»£c xÃ¢y dá»±ng vá»›i â¤ï¸ bá»Ÿi sinh viÃªn UIT**

</div>
