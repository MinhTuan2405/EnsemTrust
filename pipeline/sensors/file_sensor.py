from dagster import (
    sensor,
    RunRequest,
    SensorEvaluationContext,
    DefaultSensorStatus,
    SensorResult,
)
from datetime import datetime
import json


@sensor(
    name="landing_zone_file_sensor",
    description="Theo dÃµi landing zone trong MinIO vÃ  trigger ingest job khi cÃ³ file má»›i",
    job_name="ingest_file_from_landing",
    default_status=DefaultSensorStatus.RUNNING,
    minimum_interval_seconds=15,  # Check má»—i 15 giÃ¢y
    required_resource_keys={"minio_resource"},
)
def landing_zone_file_sensor(context: SensorEvaluationContext):
    """
    Sensor kiá»ƒm tra landing zone bucket trong MinIO Ä‘á»ƒ phÃ¡t hiá»‡n file má»›i.
    Khi cÃ³ file má»›i, sensor sáº½ trigger job Ä‘á»ƒ ingest file vÃ o bronze layer.
    """
    
    # Láº¥y MinIO resource
    minio_client = context.resources.minio_resource
    
    landing_bucket = "landing"
    
    if not minio_client.bucket_exists(landing_bucket):
        context.log.warning(f"Landing bucket '{landing_bucket}' khÃ´ng tá»“n táº¡i. Táº¡o bucket...")
        minio_client.make_bucket(landing_bucket)
        return
    
    # Láº¥y cursor tá»« láº§n cháº¡y trÆ°á»›c (lÆ°u timestamp cá»§a file cuá»‘i cÃ¹ng Ä‘Ã£ xá»­ lÃ½)
    cursor_dict = json.loads(context.cursor) if context.cursor else {}
    last_processed_time = cursor_dict.get("last_processed_time", "")
    processed_files = set(cursor_dict.get("processed_files", []))
    
    context.log.info(f"Äang quÃ©t landing zone bucket: {landing_bucket}")
    context.log.info(f"Last processed time: {last_processed_time or 'None'}")
    
    # List táº¥t cáº£ objects trong landing bucket
    objects = minio_client.list_objects(landing_bucket, recursive=True)
    
    new_files = []
    current_files = set()
    latest_time = last_processed_time
    
    for obj in objects:
        file_name = obj.object_name
        file_time = obj.last_modified.isoformat()
        current_files.add(file_name)
        
        if file_name not in processed_files:
            new_files.append({
                "file_name": file_name,
                "size": obj.size,
                "last_modified": file_time,
                "etag": obj.etag,
            })
            
            if file_time > latest_time:
                latest_time = file_time
    
    if not new_files:
        context.log.info("KhÃ´ng cÃ³ file má»›i trong landing zone")
        return
    
    context.log.info(f"PhÃ¡t hiá»‡n {len(new_files)} file má»›i:")
    for file_info in new_files:
        context.log.info(f"  ðŸ“„ {file_info['file_name']} ({file_info['size']} bytes)")
    
    run_requests = []
    for file_info in new_files:
        run_config = {
            "ops": {
                "ingest_new_file": {
                    "config": {
                        "file_name": file_info["file_name"],
                        "file_size": file_info["size"],
                        "file_modified": file_info["last_modified"],
                    }
                }
            }
        }
        
        run_requests.append(
            RunRequest(
                run_key=f"ingest_{file_info['file_name']}_{file_info['last_modified']}",
                run_config=run_config,
                tags={
                    "source": "landing_zone_sensor",
                    "file_name": file_info["file_name"],
                    "file_size": str(file_info["size"]),
                },
            )
        )
    
    # Cáº­p nháº­t cursor vá»›i danh sÃ¡ch file Ä‘Ã£ xá»­ lÃ½
    updated_processed_files = processed_files.union({f["file_name"] for f in new_files})
    new_cursor = json.dumps({
        "last_processed_time": latest_time,
        "processed_files": list(updated_processed_files),
        "last_check": datetime.now().isoformat(),
    })
    
    return SensorResult(
        run_requests=run_requests,
        cursor=new_cursor,
    )
