"""
File Sensor - Monitor MinIO Landing Zone for New Files
Sensor n√†y theo d√µi landing zone trong MinIO v√† trigger job khi c√≥ file m·ªõi
"""
from dagster import (
    sensor,
    RunRequest,
    SensorEvaluationContext,
    DefaultSensorStatus,
    AssetMaterialization,
    SensorResult,
)
from datetime import datetime
import json


@sensor(
    name="landing_zone_file_sensor",
    description="Theo d√µi landing zone trong MinIO v√† trigger ingest job khi c√≥ file m·ªõi",
    default_status=DefaultSensorStatus.RUNNING,
    minimum_interval_seconds=30,  # Check m·ªói 30 gi√¢y
    required_resource_keys={"minio_resource"},
)
def landing_zone_file_sensor(context: SensorEvaluationContext):
    """
    Sensor ki·ªÉm tra landing zone bucket trong MinIO ƒë·ªÉ ph√°t hi·ªán file m·ªõi.
    Khi c√≥ file m·ªõi, sensor s·∫Ω trigger job ƒë·ªÉ ingest file v√†o bronze layer.
    """
    
    # L·∫•y MinIO resource
    minio_client = context.resources.minio_resource
    
    landing_bucket = "landing"
    
    # Ki·ªÉm tra bucket t·ªìn t·∫°i
    if not minio_client.bucket_exists(landing_bucket):
        context.log.warning(f"‚ö†Ô∏è Landing bucket '{landing_bucket}' kh√¥ng t·ªìn t·∫°i. T·∫°o bucket...")
        minio_client.make_bucket(landing_bucket)
        return
    
    # L·∫•y cursor t·ª´ l·∫ßn ch·∫°y tr∆∞·ªõc (l∆∞u timestamp c·ªßa file cu·ªëi c√πng ƒë√£ x·ª≠ l√Ω)
    cursor_dict = json.loads(context.cursor) if context.cursor else {}
    last_processed_time = cursor_dict.get("last_processed_time", "")
    processed_files = set(cursor_dict.get("processed_files", []))
    
    context.log.info(f"üîç ƒêang qu√©t landing zone bucket: {landing_bucket}")
    context.log.info(f"üìÖ Last processed time: {last_processed_time or 'None'}")
    
    # List t·∫•t c·∫£ objects trong landing bucket
    objects = minio_client.list_objects(landing_bucket, recursive=True)
    
    new_files = []
    current_files = set()
    latest_time = last_processed_time
    
    for obj in objects:
        file_name = obj.object_name
        file_time = obj.last_modified.isoformat()
        current_files.add(file_name)
        
        # Ki·ªÉm tra file m·ªõi (ch∆∞a ƒë∆∞·ª£c x·ª≠ l√Ω)
        if file_name not in processed_files:
            new_files.append({
                "file_name": file_name,
                "size": obj.size,
                "last_modified": file_time,
                "etag": obj.etag,
            })
            
            # C·∫≠p nh·∫≠t latest_time
            if file_time > latest_time:
                latest_time = file_time
    
    if not new_files:
        context.log.info("‚úÖ Kh√¥ng c√≥ file m·ªõi trong landing zone")
        return
    
    context.log.info(f"üÜï Ph√°t hi·ªán {len(new_files)} file m·ªõi:")
    for file_info in new_files:
        context.log.info(f"  üìÑ {file_info['file_name']} ({file_info['size']} bytes)")
    
    # T·∫°o RunRequest cho m·ªói file m·ªõi
    run_requests = []
    for file_info in new_files:
        run_config = {
            "ops": {
                "ingest_new_file": {
                    "config": {
                        "file_name": file_info["file_name"],
                        "file_size": file_info["size"],
                        "file_modified": file_info["last_modified"],
                    }
                }
            }
        }
        
        run_requests.append(
            RunRequest(
                run_key=f"ingest_{file_info['file_name']}_{file_info['last_modified']}",
                run_config=run_config,
                tags={
                    "source": "landing_zone_sensor",
                    "file_name": file_info["file_name"],
                    "file_size": str(file_info["size"]),
                },
            )
        )
    
    # C·∫≠p nh·∫≠t cursor v·ªõi danh s√°ch file ƒë√£ x·ª≠ l√Ω
    updated_processed_files = processed_files.union({f["file_name"] for f in new_files})
    new_cursor = json.dumps({
        "last_processed_time": latest_time,
        "processed_files": list(updated_processed_files),
        "last_check": datetime.now().isoformat(),
    })
    
    return SensorResult(
        run_requests=run_requests,
        cursor=new_cursor,
    )


@sensor(
    name="landing_zone_asset_sensor",
    description="Sensor ƒë·ªÉ trigger asset ingest_new_file khi c√≥ file m·ªõi",
    default_status=DefaultSensorStatus.RUNNING,
    minimum_interval_seconds=30,
    asset_selection=["ingest_new_file"],  # Ch·ªâ ƒë·ªãnh asset c·∫ßn materialize
    required_resource_keys={"minio_resource"},
)
def landing_zone_asset_sensor(context: SensorEvaluationContext):
    """
    Alternative sensor s·ª≠ d·ª•ng asset materialization approach.
    Sensor n√†y tr·ª±c ti·∫øp trigger asset thay v√¨ job.
    """
    
    minio_client = context.resources.minio_resource
    landing_bucket = "landing"
    
    if not minio_client.bucket_exists(landing_bucket):
        context.log.warning(f"‚ö†Ô∏è Bucket '{landing_bucket}' ch∆∞a t·ªìn t·∫°i")
        minio_client.make_bucket(landing_bucket)
        return
    
    # Load cursor
    cursor_dict = json.loads(context.cursor) if context.cursor else {}
    processed_files = set(cursor_dict.get("processed_files", []))
    
    # Scan for new files
    objects = list(minio_client.list_objects(landing_bucket, recursive=True))
    
    new_files = []
    for obj in objects:
        if obj.object_name not in processed_files:
            new_files.append({
                "name": obj.object_name,
                "size": obj.size,
                "modified": obj.last_modified.isoformat(),
            })
    
    if not new_files:
        return
    
    context.log.info(f"üÜï Ph√°t hi·ªán {len(new_files)} file m·ªõi - triggering asset materialization")
    
    # T·∫°o RunRequest ƒë·ªÉ materialize asset
    run_requests = []
    for file_info in new_files:
        run_requests.append(
            RunRequest(
                run_key=f"asset_ingest_{file_info['name']}_{file_info['modified']}",
                tags={
                    "file_name": file_info["name"],
                    "file_size": str(file_info["size"]),
                    "trigger": "landing_zone_sensor",
                },
            )
        )
    
    # Update cursor
    all_processed = processed_files.union({f["name"] for f in new_files})
    new_cursor = json.dumps({
        "processed_files": list(all_processed),
        "last_check": datetime.now().isoformat(),
    })
    
    return SensorResult(
        run_requests=run_requests,
        cursor=new_cursor,
    )
