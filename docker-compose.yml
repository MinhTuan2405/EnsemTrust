services:
  postgres:
    image: postgres:latest
    container_name: postgres
    env_file: ./.env
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - ./data/postgres:/var/lib/postgresql
      - ./init-scripts/postgres:/docker-entrypoint-initdb.d
    ports:
      - "${POSTGRES_PORT}:5432"
    networks:
      - ensemtrust_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 10
    command:
      - "postgres"
      - "-c"
      - "wal_level=logical"
      - "-c"
      - "max_wal_senders=10"
      - "-c"
      - "max_replication_slots=10"
    restart: on-failure

  dagster:
    build:
      context: .
      dockerfile: Dockerfile.dagster
    container_name: dagster
    env_file: ./.env
    environment:
      - DAGSTER_ENV=${DAGSTER_ENV}
      - DAGSTER_HOME=${DAGSTER_HOME}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_PORT=${CONTAINER_POSTGRES_PORT}
      - DATABASE_URL=${DATABASE_URL}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
      - AWS_S3_ENDPOINT=${AWS_S3_ENDPOINT}
    volumes:
      - ./workspace.yaml:/opt/dagster/dagster_home/dagster-project/workspace.yaml:ro
      - ./pipeline:/opt/dagster/dagster_home/dagster-project/pipeline
      - ./data/dagster/compute_logs:/opt/dagster/dagster_home/dagster-project/compute_logs
      - ./data/dagster/storage:/opt/dagster/dagster_home/dagster-project/storage
      - ./data/dagster/local_artifact_storage:/opt/dagster/dagster_home/dagster-project/local_artifact_storage
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "${DAGSTER_PORT}:3000"
    networks:
      - ensemtrust_network
    depends_on:
      postgres:
        condition: service_healthy
    restart: on-failure

  minio:
    image: minio/minio:latest
    container_name: minio
    env_file: ./.env
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":${MINIO_CONSOLE_PORT:-9001}" --address ":9000"
    volumes:
      - ./data/minio:/data
    ports:
      - "${MINIO_PORT:-9000}:9000"
      - "${MINIO_CONSOLE_PORT:-9001}:9001"
    networks:
      - ensemtrust_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/ready"]
      interval: 5s
      timeout: 3s
      retries: 20
    restart: on-failure

  mc:
    image: minio/mc:latest
    container_name: mc
    env_file: ./.env
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: ["/bin/sh"]
    command:
      - -ec
      - |
        until mc alias set local http://minio:9000 ${MINIO_ROOT_USER:-minioadmin} ${MINIO_ROOT_PASSWORD:-minioadmin}; do echo 'waiting for minio...'; sleep 2; done
        mc mb -p local/bronze || true
        mc mb -p local/silver || true
        mc mb -p local/gold || true
        mc version enable local/bronze || true
        mc version enable local/silver || true
        mc version enable local/gold || true
    networks:
      - ensemtrust_network
    restart: "no"

  spark-master:
    image: apache/spark:3.5.1-python3
    hostname: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    env_file:
      - ./.env
    ports:
      - "8080:8080"  # Spark Master Web UI
      - "7077:7077"  
    networks:
      - ensemtrust_network
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
    volumes:
      - ./spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    depends_on:
      minio:
        condition: service_healthy
      postgres:
        condition: service_healthy
    healthcheck:  
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  spark-worker:
    image: apache/spark:3.5.1-python3
    hostname: spark-worker
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    env_file:
      - ./.env
    depends_on:
      spark-master:
          condition: service_healthy
    ports:
      - "8081:8081"
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
    networks:
      - ensemtrust_network
    volumes:
      - ./spark-defaults.conf:/opt/spark/conf/spark-defaults.conf

  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1 
    container_name: zookeeper
    env_file:
      - ./.env
    networks:
      - ensemtrust_network
    ports:
      - "2181:2181"
    volumes:
      - ./data/zookeeper/data:/var/lib/zookeeper/data
      - ./data/zookeeper/log:/var/lib/zookeeper/log
    environment:
      - ZOOKEEPER_CLIENT_PORT=${ZOOKEEPER_CLIENT_PORT}
      - ZOOKEEPER_TICK_TIME=${ZOOKEEPER_TICK_TIME}
    healthcheck:
      test: ["CMD-SHELL", "echo ruok | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: on-failure

  kafka:
    image: confluentinc/cp-kafka:7.6.1 
    container_name: kafka
    env_file:
      - ./.env
    networks:
      - ensemtrust_network
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9094:9094" # external port
    volumes:
      - ./data/kafka/data:/var/lib/kafka/data
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_BROKER: 'kafka:9092'

      
      KAFKA_LISTENERS: INTERNAL://:9092,EXTERNAL://:9094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_NUM_PARTITIONS: 3

      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
    healthcheck:
      test: ["CMD-SHELL", "cub kafka-ready -b localhost:9092 -n 1"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 10s
    restart: on-failure

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    env_file:
      - ./.env
    ports:
      - "${KAFKA_UI_PORT:-8088}:8080" 
    networks:
      - ensemtrust_network
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_CLUSTERS_0_NAME: local-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092 
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      DYNAMIC_CONFIG_ENABLED: "true"
    restart: on-failure
      

  hive-metastore:
    image: apache/hive:4.0.0
    container_name: hive-metastore
    env_file: ./.env
    environment:
      - SERVICE_NAME=metastore
      - DB_DRIVER=postgres
      - SERVICE_OPTS=-Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres:5432/${POSTGRES_DB} -Djavax.jdo.option.ConnectionUserName=${POSTGRES_USER} -Djavax.jdo.option.ConnectionPassword=${POSTGRES_PASSWORD}
      # include both the versioned jar name and a common alias so the metastore finds the driver
      - HIVE_AUX_JARS_PATH=/opt/hive/lib/postgresql-42.7.8.jar:/opt/hive/lib/postgresql-driver.jar:/opt/hive/lib/hadoop-aws.jar:/opt/hive/lib/aws-java-sdk-bundle.jar
      - HADOOP_CLASSPATH=/opt/hive/lib/postgresql-42.7.8.jar:/opt/hive/lib/postgresql-driver.jar:/opt/hive/lib/hadoop-aws.jar:/opt/hive/lib/aws-java-sdk-bundle.jar
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-admin}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD:-admin123}
    ports:
      - "9083:9083"
    volumes:
      # Mount JDBC and Hadoop AWS JAR files
      # - ./jars/postgresql-42.7.8.jar:/opt/hive/lib/postgresql-42.7.8.jar:ro
      # also mount as a generic driver name (some Hive images expect this filename)
      - ./jars/postgresql-42.7.8.jar:/opt/hive/lib/postgresql-driver.jar:ro
      - ./jars/hadoop-aws-3.3.6.jar:/opt/hive/lib/hadoop-aws.jar:ro
      - ./jars/aws-java-sdk-bundle-1.12.262.jar:/opt/hive/lib/aws-java-sdk-bundle.jar:ro
      # Mount hive configuration
      - ./config/hive/hive-site.xml:/opt/hive/conf/hive-site.xml:ro
    networks:
      - ensemtrust_network
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_healthy
    restart: on-failure

  trino:
    image: trinodb/trino:latest
    container_name: trino
    env_file: ./.env
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: admin123
    volumes:
      - ./config/trino:/etc/trino
      - ./data/trino:/data/trino
      - ./jars/hadoop-aws-3.3.6.jar:/usr/lib/trino/plugin/delta-lake/hadoop-aws-3.3.6.jar:ro
      - ./jars/aws-java-sdk-bundle-1.12.262.jar:/usr/lib/trino/plugin/delta-lake/aws-java-sdk-bundle-1.12.262.jar:ro
    ports:
      - "${TRINO_PORT:-8090}:8080"
    networks:
      - ensemtrust_network
    depends_on:
      minio:
        condition: service_healthy
      hive-metastore:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/info"]
      interval: 10s
      timeout: 5s
      retries: 30
    restart: on-failure


  cloudbeaver:
    image: dbeaver/cloudbeaver:latest
    container_name: cloudbeaver
    env_file: ./.env
    volumes:
      - ./data/cloudbeaver:/opt/cloudbeaver/workspace
    ports:
      - "${CLOUDBEAVER_PORT:-8978}:8978"
    networks:
      - ensemtrust_network
    depends_on:
      trino:
        condition: service_healthy
    restart: on-failure

  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    networks:
      - ensemtrust_network 
    ports:
      - "3007:3000"
    env_file: ./.env
    environment:
      MB_DB_TYPE: postgres
      MB_DB_HOST: postgres 
      MB_DB_PORT: 5432
      MB_DB_DBNAME: ${METABASE_DB} 
      MB_DB_USER: ${POSTGRES_USER}
      MB_DB_PASS: ${POSTGRES_PASSWORD}
      MB_ANONYMOUS_TRACKING: "false"
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s 
    restart: on-failure

  streamlit:
    build:
      context: .
      dockerfile: Dockerfile.streamlit
    container_name: streamlit
    networks:
      - ensemtrust_network
    ports:
      - "8501:8501" 
    env_file: ./.env
    environment:
      - TRINO_HOST=trino
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB} 
    volumes:
      - ./streamlit:/app
    depends_on:
      trino:
        condition: service_healthy
      postgres:
        condition: service_healthy
    restart: on-failure
  
  
networks:
  ensemtrust_network:
    driver: bridge