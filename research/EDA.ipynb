{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec20658",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5326b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed46781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from MinIO or local files\n",
    "# Option 1: From MinIO (if running in environment)\n",
    "# from minio import Minio\n",
    "# from io import BytesIO\n",
    "# minio_client = Minio(...)\n",
    "# df = pd.read_parquet(BytesIO(...))\n",
    "\n",
    "# Option 2: From local CSV files\n",
    "fake_df = pd.read_csv(\"../data/Fake.csv\") if os.path.exists(\"../data/Fake.csv\") else pd.read_csv(\"Fake.csv\")\n",
    "real_df = pd.read_csv(\"../data/True.csv\") if os.path.exists(\"../data/True.csv\") else pd.read_csv(\"True.csv\")\n",
    "\n",
    "# Add labels\n",
    "fake_df['label'] = 0\n",
    "real_df['label'] = 1\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([fake_df, real_df], ignore_index=True)\n",
    "\n",
    "print(f\"✓ Data loaded successfully\")\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Fake news: {len(fake_df):,}\")\n",
    "print(f\"Real news: {len(real_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398adcbc",
   "metadata": {},
   "source": [
    "## 2. Basic Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098382fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset shape\n",
    "print(\"=\"*50)\n",
    "print(\"DATASET SHAPE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Rows: {df.shape[0]:,}\")\n",
    "print(f\"Columns: {df.shape[1]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c9f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First few rows\n",
    "print(\"=\"*50)\n",
    "print(\"FIRST 5 ROWS\")\n",
    "print(\"=\"*50)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cccac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and memory usage\n",
    "print(\"=\"*50)\n",
    "print(\"DATA TYPES & MEMORY USAGE\")\n",
    "print(\"=\"*50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb91440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"=\"*50)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c2e12",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "print(\"=\"*50)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum().values,\n",
    "    'Missing_Percentage': (df.isnull().sum().values / len(df) * 100).round(2)\n",
    "})\n",
    "\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "if len(missing_data) > 0:\n",
    "    print(missing_data)\n",
    "    \n",
    "    # Visualize missing values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=missing_data, x='Column', y='Missing_Percentage')\n",
    "    plt.title('Missing Values by Column (%)', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Column')\n",
    "    plt.ylabel('Missing Percentage (%)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"✓ No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec0440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate records\n",
    "print(\"=\"*50)\n",
    "print(\"DUPLICATE ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Total duplicates: {duplicates:,} ({duplicates/len(df)*100:.2f}%)\")\n",
    "\n",
    "if 'text' in df.columns:\n",
    "    text_duplicates = df.duplicated(subset=['text']).sum()\n",
    "    print(f\"Duplicate texts: {text_duplicates:,} ({text_duplicates/len(df)*100:.2f}%)\")\n",
    "\n",
    "if 'title' in df.columns:\n",
    "    title_duplicates = df.duplicated(subset=['title']).sum()\n",
    "    print(f\"Duplicate titles: {title_duplicates:,} ({title_duplicates/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3373fc6",
   "metadata": {},
   "source": [
    "## 4. Target Variable Analysis (Label Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae88b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label distribution\n",
    "print(\"=\"*50)\n",
    "print(\"LABEL DISTRIBUTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "label_counts = df['label'].value_counts()\n",
    "label_pcts = df['label'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(f\"Fake (0): {label_counts[0]:,} ({label_pcts[0]:.2f}%)\")\n",
    "print(f\"Real (1): {label_counts[1]:,} ({label_pcts[1]:.2f}%)\")\n",
    "print(f\"\\nBalance Ratio: 1:{label_counts[1]/label_counts[0]:.2f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "label_counts.plot(kind='bar', ax=axes[0], color=['#FF6B6B', '#4ECDC4'])\n",
    "axes[0].set_title('Label Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Label (0=Fake, 1=Real)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(['Fake', 'Real'], rotation=0)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, v in enumerate(label_counts):\n",
    "    axes[0].text(i, v + 500, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#FF6B6B', '#4ECDC4']\n",
    "axes[1].pie(label_counts, labels=['Fake', 'Real'], autopct='%1.1f%%', \n",
    "            colors=colors, startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Label Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3781d4ae",
   "metadata": {},
   "source": [
    "## 5. Text Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c1a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate text lengths if not already present\n",
    "if 'text_length' not in df.columns and 'text' in df.columns:\n",
    "    df['text_length'] = df['text'].apply(lambda x: len(str(x)) if pd.notna(x) else 0)\n",
    "\n",
    "if 'title_length' not in df.columns and 'title' in df.columns:\n",
    "    df['title_length'] = df['title'].apply(lambda x: len(str(x)) if pd.notna(x) else 0)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"TEXT LENGTH STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Overall statistics\n",
    "if 'text_length' in df.columns:\n",
    "    print(\"\\nText Length:\")\n",
    "    print(df['text_length'].describe())\n",
    "    \n",
    "if 'title_length' in df.columns:\n",
    "    print(\"\\nTitle Length:\")\n",
    "    print(df['title_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cacf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length by label\n",
    "if 'text_length' in df.columns:\n",
    "    print(\"=\"*50)\n",
    "    print(\"TEXT LENGTH BY LABEL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    text_length_by_label = df.groupby('label')['text_length'].agg(['mean', 'median', 'min', 'max', 'std'])\n",
    "    text_length_by_label.index = ['Fake (0)', 'Real (1)']\n",
    "    print(text_length_by_label)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Distribution by label\n",
    "    fake_text_len = df[df['label'] == 0]['text_length']\n",
    "    real_text_len = df[df['label'] == 1]['text_length']\n",
    "    \n",
    "    axes[0, 0].hist([fake_text_len, real_text_len], bins=50, label=['Fake', 'Real'], \n",
    "                    color=['#FF6B6B', '#4ECDC4'], alpha=0.7)\n",
    "    axes[0, 0].set_title('Text Length Distribution by Label', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Text Length')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Box plot\n",
    "    df.boxplot(column='text_length', by='label', ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('Text Length Box Plot by Label', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Label (0=Fake, 1=Real)')\n",
    "    axes[0, 1].set_ylabel('Text Length')\n",
    "    axes[0, 1].set_xticklabels(['Fake', 'Real'])\n",
    "    plt.suptitle('')\n",
    "    \n",
    "    # Violin plot\n",
    "    sns.violinplot(data=df, x='label', y='text_length', ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Text Length Violin Plot by Label', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Label')\n",
    "    axes[1, 0].set_ylabel('Text Length')\n",
    "    axes[1, 0].set_xticklabels(['Fake', 'Real'])\n",
    "    \n",
    "    # Mean comparison\n",
    "    mean_lengths = df.groupby('label')['text_length'].mean()\n",
    "    axes[1, 1].bar(['Fake', 'Real'], mean_lengths, color=['#FF6B6B', '#4ECDC4'])\n",
    "    axes[1, 1].set_title('Average Text Length by Label', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Label')\n",
    "    axes[1, 1].set_ylabel('Average Text Length')\n",
    "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for i, v in enumerate(mean_lengths):\n",
    "        axes[1, 1].text(i, v + 50, f'{v:.0f}', ha='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ac6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title length analysis\n",
    "if 'title_length' in df.columns:\n",
    "    print(\"=\"*50)\n",
    "    print(\"TITLE LENGTH BY LABEL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    title_length_by_label = df.groupby('label')['title_length'].agg(['mean', 'median', 'min', 'max', 'std'])\n",
    "    title_length_by_label.index = ['Fake (0)', 'Real (1)']\n",
    "    print(title_length_by_label)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Box plot\n",
    "    df.boxplot(column='title_length', by='label', ax=axes[0])\n",
    "    axes[0].set_title('Title Length Box Plot by Label', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Label (0=Fake, 1=Real)')\n",
    "    axes[0].set_ylabel('Title Length')\n",
    "    axes[0].set_xticklabels(['Fake', 'Real'])\n",
    "    plt.suptitle('')\n",
    "    \n",
    "    # Mean comparison\n",
    "    mean_title_lengths = df.groupby('label')['title_length'].mean()\n",
    "    axes[1].bar(['Fake', 'Real'], mean_title_lengths, color=['#FF6B6B', '#4ECDC4'])\n",
    "    axes[1].set_title('Average Title Length by Label', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Label')\n",
    "    axes[1].set_ylabel('Average Title Length')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for i, v in enumerate(mean_title_lengths):\n",
    "        axes[1].text(i, v + 2, f'{v:.1f}', ha='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc98a9",
   "metadata": {},
   "source": [
    "## 6. Subject/Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c744d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject distribution\n",
    "if 'subject' in df.columns:\n",
    "    print(\"=\"*50)\n",
    "    print(\"SUBJECT DISTRIBUTION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    subject_counts = df['subject'].value_counts()\n",
    "    print(subject_counts)\n",
    "    print(f\"\\nTotal unique subjects: {df['subject'].nunique()}\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Bar plot\n",
    "    subject_counts.plot(kind='barh', ax=axes[0], color='skyblue')\n",
    "    axes[0].set_title('Subject Distribution (All)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Count')\n",
    "    axes[0].set_ylabel('Subject')\n",
    "    axes[0].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Pie chart (top subjects)\n",
    "    top_subjects = subject_counts.head(10)\n",
    "    axes[1].pie(top_subjects, labels=top_subjects.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[1].set_title('Top 10 Subjects Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f280451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject distribution by label\n",
    "if 'subject' in df.columns:\n",
    "    print(\"=\"*50)\n",
    "    print(\"SUBJECT DISTRIBUTION BY LABEL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    subject_by_label = pd.crosstab(df['subject'], df['label'])\n",
    "    subject_by_label.columns = ['Fake', 'Real']\n",
    "    print(subject_by_label)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Stacked bar chart\n",
    "    subject_by_label.plot(kind='bar', stacked=True, ax=axes[0], color=['#FF6B6B', '#4ECDC4'])\n",
    "    axes[0].set_title('Subject Distribution by Label (Stacked)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Subject')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].legend(title='Label')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Grouped bar chart\n",
    "    subject_by_label.plot(kind='bar', ax=axes[1], color=['#FF6B6B', '#4ECDC4'])\n",
    "    axes[1].set_title('Subject Distribution by Label (Grouped)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Subject')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].legend(title='Label')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa7a84",
   "metadata": {},
   "source": [
    "## 7. Temporal Analysis (Date, Year, Month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6f258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date column if exists\n",
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    \n",
    "    # Extract temporal features if not present\n",
    "    if 'year' not in df.columns:\n",
    "        df['year'] = df['date'].dt.year.astype(str)\n",
    "    if 'month' not in df.columns:\n",
    "        df['month'] = df['date'].dt.month_name()\n",
    "    if 'year_month' not in df.columns:\n",
    "        df['year_month'] = df['date'].dt.to_period('M').astype(str)\n",
    "\n",
    "print(\"✓ Temporal features processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d3be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year distribution\n",
    "if 'year' in df.columns:\n",
    "    print(\"=\"*50)\n",
    "    print(\"YEAR DISTRIBUTION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    year_counts = df['year'].value_counts().sort_index()\n",
    "    print(year_counts)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Overall year distribution\n",
    "    year_counts.plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "    axes[0].set_title('News Articles by Year', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Year')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Year distribution by label\n",
    "    year_by_label = pd.crosstab(df['year'], df['label'])\n",
    "    year_by_label.columns = ['Fake', 'Real']\n",
    "    year_by_label.plot(kind='bar', ax=axes[1], color=['#FF6B6B', '#4ECDC4'])\n",
    "    axes[1].set_title('News Articles by Year and Label', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Year')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].legend(title='Label')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month distribution\n",
    "if 'month' in df.columns:\n",
    "    print(\"=\"*50)\n",
    "    print(\"MONTH DISTRIBUTION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Order months correctly\n",
    "    month_order = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "                   'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    \n",
    "    month_counts = df['month'].value_counts().reindex(month_order, fill_value=0)\n",
    "    print(month_counts)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Overall month distribution\n",
    "    month_counts.plot(kind='bar', ax=axes[0], color='coral')\n",
    "    axes[0].set_title('News Articles by Month', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Month')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Month distribution by label\n",
    "    month_by_label = pd.crosstab(df['month'], df['label']).reindex(month_order, fill_value=0)\n",
    "    month_by_label.columns = ['Fake', 'Real']\n",
    "    month_by_label.plot(kind='bar', ax=axes[1], color=['#FF6B6B', '#4ECDC4'])\n",
    "    axes[1].set_title('News Articles by Month and Label', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Month')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].legend(title='Label')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc83b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series analysis\n",
    "if 'year_month' in df.columns:\n",
    "    print(\"=\"*50)\n",
    "    print(\"TIME SERIES ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Time series by label\n",
    "    time_series = df.groupby(['year_month', 'label']).size().unstack(fill_value=0)\n",
    "    time_series.columns = ['Fake', 'Real']\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "    \n",
    "    # Line plot\n",
    "    time_series.plot(ax=axes[0], color=['#FF6B6B', '#4ECDC4'], linewidth=2, marker='o')\n",
    "    axes[0].set_title('News Articles Over Time by Label', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Year-Month')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].legend(title='Label')\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Stacked area plot\n",
    "    time_series.plot.area(ax=axes[1], color=['#FF6B6B', '#4ECDC4'], alpha=0.7)\n",
    "    axes[1].set_title('Cumulative News Articles Over Time by Label', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Year-Month')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].legend(title='Label')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a6dda",
   "metadata": {},
   "source": [
    "## 8. Word Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional libraries if needed\n",
    "# !pip install wordcloud nltk\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Download stopwords\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "print(\"✓ Word analysis libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c3131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word count analysis\n",
    "if 'text' in df.columns:\n",
    "    print(\"=\"*50)\n",
    "    print(\"WORD COUNT ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    df['word_count'] = df['text'].apply(lambda x: len(str(x).split()) if pd.notna(x) else 0)\n",
    "    \n",
    "    word_count_stats = df.groupby('label')['word_count'].agg(['mean', 'median', 'min', 'max', 'std'])\n",
    "    word_count_stats.index = ['Fake (0)', 'Real (1)']\n",
    "    print(word_count_stats)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Box plot\n",
    "    df.boxplot(column='word_count', by='label', ax=axes[0])\n",
    "    axes[0].set_title('Word Count Distribution by Label', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Label (0=Fake, 1=Real)')\n",
    "    axes[0].set_ylabel('Word Count')\n",
    "    axes[0].set_xticklabels(['Fake', 'Real'])\n",
    "    plt.suptitle('')\n",
    "    \n",
    "    # Mean comparison\n",
    "    mean_word_counts = df.groupby('label')['word_count'].mean()\n",
    "    axes[1].bar(['Fake', 'Real'], mean_word_counts, color=['#FF6B6B', '#4ECDC4'])\n",
    "    axes[1].set_title('Average Word Count by Label', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Label')\n",
    "    axes[1].set_ylabel('Average Word Count')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for i, v in enumerate(mean_word_counts):\n",
    "        axes[1].text(i, v + 5, f'{v:.0f}', ha='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ac842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common words analysis\n",
    "def get_top_words(texts, n=20, label_name=''):\n",
    "    \"\"\"Extract top N most common words from texts\"\"\"\n",
    "    all_words = []\n",
    "    for text in texts:\n",
    "        if pd.notna(text):\n",
    "            # Clean and tokenize\n",
    "            words = re.findall(r'\\b[a-zA-Z]{3,}\\b', str(text).lower())\n",
    "            # Filter stopwords\n",
    "            words = [w for w in words if w not in stop_words]\n",
    "            all_words.extend(words)\n",
    "    \n",
    "    word_counts = Counter(all_words)\n",
    "    return word_counts.most_common(n)\n",
    "\n",
    "if 'text' in df.columns:\n",
    "    print(\"=\"*50)\n",
    "    print(\"MOST COMMON WORDS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Top words for fake news\n",
    "    fake_texts = df[df['label'] == 0]['text']\n",
    "    top_fake_words = get_top_words(fake_texts, n=20)\n",
    "    \n",
    "    print(\"\\nTop 20 words in FAKE news:\")\n",
    "    for word, count in top_fake_words:\n",
    "        print(f\"{word}: {count}\")\n",
    "    \n",
    "    # Top words for real news\n",
    "    real_texts = df[df['label'] == 1]['text']\n",
    "    top_real_words = get_top_words(real_texts, n=20)\n",
    "    \n",
    "    print(\"\\nTop 20 words in REAL news:\")\n",
    "    for word, count in top_real_words:\n",
    "        print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top words\n",
    "if 'text' in df.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Fake news top words\n",
    "    fake_words_df = pd.DataFrame(top_fake_words, columns=['Word', 'Count'])\n",
    "    axes[0].barh(fake_words_df['Word'], fake_words_df['Count'], color='#FF6B6B')\n",
    "    axes[0].set_title('Top 20 Words in FAKE News', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Frequency')\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Real news top words\n",
    "    real_words_df = pd.DataFrame(top_real_words, columns=['Word', 'Count'])\n",
    "    axes[1].barh(real_words_df['Word'], real_words_df['Count'], color='#4ECDC4')\n",
    "    axes[1].set_title('Top 20 Words in REAL News', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Frequency')\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1305c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word clouds\n",
    "if 'text' in df.columns:\n",
    "    print(\"Generating word clouds...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Fake news word cloud\n",
    "    fake_text = ' '.join(df[df['label'] == 0]['text'].astype(str))\n",
    "    wordcloud_fake = WordCloud(width=800, height=400, \n",
    "                               background_color='white',\n",
    "                               stopwords=stop_words,\n",
    "                               colormap='Reds').generate(fake_text)\n",
    "    \n",
    "    axes[0].imshow(wordcloud_fake, interpolation='bilinear')\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('Word Cloud - FAKE News', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Real news word cloud\n",
    "    real_text = ' '.join(df[df['label'] == 1]['text'].astype(str))\n",
    "    wordcloud_real = WordCloud(width=800, height=400,\n",
    "                               background_color='white',\n",
    "                               stopwords=stop_words,\n",
    "                               colormap='Blues').generate(real_text)\n",
    "    \n",
    "    axes[1].imshow(wordcloud_real, interpolation='bilinear')\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Word Cloud - REAL News', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Word clouds generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab7552",
   "metadata": {},
   "source": [
    "## 9. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical features\n",
    "print(\"=\"*50)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "\n",
    "if len(numerical_cols) > 1:\n",
    "    correlation_matrix = df[numerical_cols].corr()\n",
    "    print(\"\\nCorrelation Matrix:\")\n",
    "    print(correlation_matrix)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1)\n",
    "    plt.title('Correlation Matrix - Numerical Features', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation with label\n",
    "    if 'label' in numerical_cols:\n",
    "        label_corr = correlation_matrix['label'].sort_values(ascending=False)\n",
    "        print(\"\\nCorrelation with Label:\")\n",
    "        print(label_corr)\n",
    "        \n",
    "        # Visualize correlation with label\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        label_corr.drop('label').plot(kind='barh', color='steelblue')\n",
    "        plt.title('Feature Correlation with Label', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Correlation Coefficient')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.axvline(x=0, color='red', linestyle='--', linewidth=1)\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf434a4",
   "metadata": {},
   "source": [
    "## 10. Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c67bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical significance tests\n",
    "from scipy import stats\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"STATISTICAL SIGNIFICANCE TESTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# T-test for text length\n",
    "if 'text_length' in df.columns:\n",
    "    fake_text_len = df[df['label'] == 0]['text_length']\n",
    "    real_text_len = df[df['label'] == 1]['text_length']\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(fake_text_len, real_text_len)\n",
    "    \n",
    "    print(\"\\nT-Test: Text Length (Fake vs Real)\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4e}\")\n",
    "    print(f\"Significant difference: {'YES' if p_value < 0.05 else 'NO'} (α=0.05)\")\n",
    "\n",
    "# T-test for title length\n",
    "if 'title_length' in df.columns:\n",
    "    fake_title_len = df[df['label'] == 0]['title_length']\n",
    "    real_title_len = df[df['label'] == 1]['title_length']\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(fake_title_len, real_title_len)\n",
    "    \n",
    "    print(\"\\nT-Test: Title Length (Fake vs Real)\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4e}\")\n",
    "    print(f\"Significant difference: {'YES' if p_value < 0.05 else 'NO'} (α=0.05)\")\n",
    "\n",
    "# Chi-square test for subject distribution\n",
    "if 'subject' in df.columns:\n",
    "    subject_label_contingency = pd.crosstab(df['subject'], df['label'])\n",
    "    chi2, p_value, dof, expected = stats.chi2_contingency(subject_label_contingency)\n",
    "    \n",
    "    print(\"\\nChi-Square Test: Subject vs Label\")\n",
    "    print(f\"Chi-square statistic: {chi2:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4e}\")\n",
    "    print(f\"Degrees of freedom: {dof}\")\n",
    "    print(f\"Significant association: {'YES' if p_value < 0.05 else 'NO'} (α=0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d95bd",
   "metadata": {},
   "source": [
    "## 11. Summary & Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EDA SUMMARY - KEY FINDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n1. DATASET OVERVIEW\")\n",
    "print(f\"   - Total records: {len(df):,}\")\n",
    "print(f\"   - Features: {df.shape[1]}\")\n",
    "print(f\"   - Fake news: {(df['label']==0).sum():,} ({(df['label']==0).sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"   - Real news: {(df['label']==1).sum():,} ({(df['label']==1).sum()/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n2. DATA QUALITY\")\n",
    "print(f\"   - Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"   - Duplicate records: {df.duplicated().sum()}\")\n",
    "\n",
    "if 'text_length' in df.columns:\n",
    "    print(f\"\\n3. TEXT CHARACTERISTICS\")\n",
    "    print(f\"   - Avg text length (Fake): {df[df['label']==0]['text_length'].mean():.0f} chars\")\n",
    "    print(f\"   - Avg text length (Real): {df[df['label']==1]['text_length'].mean():.0f} chars\")\n",
    "\n",
    "if 'title_length' in df.columns:\n",
    "    print(f\"   - Avg title length (Fake): {df[df['label']==0]['title_length'].mean():.1f} chars\")\n",
    "    print(f\"   - Avg title length (Real): {df[df['label']==1]['title_length'].mean():.1f} chars\")\n",
    "\n",
    "if 'subject' in df.columns:\n",
    "    print(f\"\\n4. SUBJECT DISTRIBUTION\")\n",
    "    print(f\"   - Unique subjects: {df['subject'].nunique()}\")\n",
    "    print(f\"   - Most common subject: {df['subject'].value_counts().index[0]}\")\n",
    "\n",
    "if 'year' in df.columns:\n",
    "    print(f\"\\n5. TEMPORAL DISTRIBUTION\")\n",
    "    years = df['year'].dropna().unique()\n",
    "    print(f\"   - Year range: {sorted(years)[0] if len(years) > 0 else 'N/A'} - {sorted(years)[-1] if len(years) > 0 else 'N/A'}\")\n",
    "    print(f\"   - Most active year: {df['year'].value_counts().index[0] if len(df['year'].value_counts()) > 0 else 'N/A'}\")\n",
    "\n",
    "print(\"\\n6. RECOMMENDATIONS FOR MODELING\")\n",
    "print(\"   - Balance classes if needed (current ratio shows potential imbalance)\")\n",
    "print(\"   - Consider text length as a feature\")\n",
    "print(\"   - Use temporal features (year, month) for time-based patterns\")\n",
    "print(\"   - Subject can be a strong categorical feature\")\n",
    "print(\"   - Apply NLP techniques (TF-IDF, embeddings) for text processing\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EDA COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f6004a",
   "metadata": {},
   "source": [
    "## 12. Export Processed Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bfe370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed dataframe with additional features\n",
    "output_path = '../data/processed_dataset.csv'\n",
    "\n",
    "# Uncomment to save\n",
    "# df.to_csv(output_path, index=False)\n",
    "# print(f\"✓ Processed data saved to: {output_path}\")\n",
    "\n",
    "print(\"\\nTo save the processed dataset, uncomment the code above.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
